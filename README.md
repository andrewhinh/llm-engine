# llm-engine

A minimal LLM inference engine in Rust.

![icon](./assets/icon.jpg)

## Development

### Installation

- [rustup](https://rustup.rs/)
- [prek](https://prek.j178.dev/installation/)

```bash
prek install
```

### Commands

```bash
cargo test
cargo run
```

## Credit

- [Inside vLLM: Anatomy of a High-Throughput LLM Inference System](https://www.aleksagordic.com/blog/vllm)
- [nano-vllm](https://github.com/GeeeekExplorer/nano-vllm)
- [mini-sglang](https://github.com/sgl-project/mini-sglang)
